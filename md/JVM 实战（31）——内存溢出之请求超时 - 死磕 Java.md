> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [www.skjava.com](https://www.skjava.com/series/article/1485333188)

> 一、简介本章，我们将通过实际案例讲解一个 Web 应用的内存溢出问题，该内存溢出问题的排查涉及 Tomcat 的一些底层原理，最终排查发现是由于请求超时问题导致，我们先来看下系统的背景

一、简介
----

本章，我们将通过实际案例讲解一个 Web 应用的内存溢出问题，该内存溢出问题的排查涉及 Tomcat 的一些底层原理，最终排查发现是由于请求超时问题导致，我们先来看下系统的背景。

### 1.1 系统背景

生产环境的一个系统发生告警，拿到生产日志后出现如下字样：  
`Exception in thread "http-nio-8080-exec-1089" java.lang.OutOfMemoryError:Java heap space`。

很明显，Java 堆内存区域发生了内存溢出异常。特别要注意的是`http-nio-8080-exec-1089`，由于当时系统部署在 tomcat 中（8080 端口），所以上面这段日志的意思就是 tomacat 工作线程在处理请求时发生了内存溢出异常。

_**为什么会是 tomcat 的工作线程发生异常？**_ 这就涉及 tomcat 的一些基本原理。

### 1.2 tomcat 基本原理

首先，我们明确一点 **Tomcat 运行时本身就是一个 JVM 进程** ，我们写好的程序打包后放到 tomcat 的指定目录下，程序中的各种类会由 Tomcat 加载到它的 JVM 内存区域中，然后由 tomcat 来执行我们程序中的类：

![](http://image.skjava.com/article/series/jvm/202308102133195161.png)

tomcat 有许多自己的工作线程，它们默认会监听 8080 端口。8080 端口上收到的请求会均匀分配给这些工作线程，工作线程接收到请求后负责调用程序自身的 Servlet 进行处理。上述异常日志中的`http-nio-8080-exec-1089`，说白了就是上图中的 tomcat 工作线程，因为它负责调用 Spring 中的一大堆代码，发现运行时堆内存不够了，所以就抛出了异常。

> Spring Boot 应用可以把 web 容器直接内嵌在我们打包后的程序中，但本质还是一样的。

二、问题分析
------

知道了系统的大致情况，我们就要用 MAT 来分析下事故现场的堆内存快照了（线上系统记得加上 JVM 参数`-XX:+HeapDumpOnOutOfMemoryError`）。

### 2.1 内存快照

我们分析内存快照，首先要找到占用堆内存最大的对象。我们发现有一大堆 byte[] 数组占据了大约 8G 的内存，而当时线上机器给 Tomcat 的 JVM 堆内存也是 8G。这说明，tomcat 工作线程在处理请求时大量创建了这些 byte[] 数组，直接把堆内存占满了，从而导致内存溢出。

![](http://image.skjava.com/article/series/jvm/202308102133203092.png)

然后，我们继续分析这些 byte[] 数组到底是个啥，通过 MAT 找了很多类似下面这样的数组，每个 10MB，一共约 800 个，总量约 8G：

![](http://image.skjava.com/article/series/jvm/202308102133210553.png)

通过 MAT 的引用分析，发现这些数组都被一个名为`org.apache.tomcat.util.threads.TaskThread`的 Tomcat 类引用着，这个一看就是 Tomcat 自己的线程类。MAT 可以查看当前 JVM 中有哪些线程存在，我们发现上述种 tomcat 线程一个约 400 个，每一个引用着 2 个 byte[] 数组。

也就是说： **400 个 tomcat 工作线程同时在处理请求，每个线程创建了 2 个 10MB 的 byte[] 数组，结果就总共创建了 8G 的数组，进而导致了内存溢出** 。

![](http://image.skjava.com/article/series/jvm/202308102133214724.png)

### 2.2 请求超时

根据上述分析，我们的脑海里应该有这样一副流动画面：_1 秒钟内来了 400 个请求，导致 tomcat 的 400 个工作线程同时开始处理请求，每个线程在处理请求时会创建 2 个 10MB 的 byte[] 数组对象，用于自用，结果瞬间把 8G 内存空间占满，触发内存溢出异常_。

但是，我们通过监控系统发现，事故现场的 QPS 只有 100，而不是 400！出现这种情况只有一种可能，请求超时了，每个请求的处理时间达到 4s，这样 4s 内 400 个工作线程会在同时工作，进而导致上述问题。

![](http://image.skjava.com/article/series/jvm/202308102133220445.png)

那么现在就剩下两个问题：

1.  每个 tomcat 工作线程创建的 2 个 10MB 的 byte 数组究竟是啥？
2.  程序哪里出现了大量超时？

先来看第一个，tomcat 的配置文件中有一个`max-http-header-size:10000000`配置，根据查阅 tomcat 文档我们知道，这个是 tomcat 工作线程为请求和响应创建的数组，可以适当调小些，但是 10MB 也在合理范围内。所以，问题的根本原因就是程序超时。

我们通过程序日志发现，有大量的`Timeout Exception`字样，这是程序在通过 RPC 调用其他系统接口时抛出的，然后通过 RPC 超时参数配置发现，超时时间刚好是 4s！

也就是说，在某一段时间内，某个外部依赖系统刚好挂掉了，导致我们系统通过 RPC 调用它的接口时出现大量超时，而在超时的 4s 内，工作线程会 hang 住，从而引发内存溢出，所以 **这个 4s 请求超时的配置是根本原因** 。

![](http://image.skjava.com/article/series/jvm/202308102133229936.png)

三、系统优化
------

分析清楚了问题原因，优化就很简单了，直接将超时时间改为 1s 就可以了。这样的话，每秒 100 个请求过来，每个拥有 2 个 byte 数组，那总共就是 2G，不会将 JVM 堆内存占满，然后超过 1s 就超时，请求结束。

> 超时时间的配置要根据系统运行时模型合理配置。除此之外，一些核心系统，必须要有熔断、降级、限流的机制，可以通过 Hystrix 来实现，没有接触过的读者可以参阅 [Hystrix 官方资料](https://github.com/Netflix/Hystrix/wiki)或阅读我的[分布式系列](https://www.tpvlog.com/article/62)了解。

四、总结
----

本章，我们通过一个实际案例分析了因为请求超时引起的内存溢出问题，以及相应的排查思路。解决这类问题的思路其实都是一致的，需要一步步去分析，在实践中积累经验，举一反三。