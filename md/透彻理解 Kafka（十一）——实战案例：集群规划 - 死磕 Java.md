> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [www.skjava.com](https://www.skjava.com/series/article/6898352029)

> 讲解完了 Kafka 的各个组件的核心工作原理，接下来的章节我会通过一个实际生产案例介绍 Kafka 的使用，我们先来看下整个案例的背景。一、案例背景我们生产环境运行着一个中小型的电商

讲解完了 Kafka 的各个组件的核心工作原理，接下来的章节我会通过一个实际生产案例介绍 Kafka 的使用，我们先来看下整个案例的背景。

一、案例背景
------

我们生产环境运行着一个中小型的电商平台，假设用户量为 1000W，我们需要通过 Kafka 来对各类数据进行采集，那么问题来了，1000W 的用户量每天会生成多大的数据呢？数据量的评估对 Kafka 的部署至关重要。

这种中小型电商网站，每天的数据来源主要有三部分构成：

1.  用户行为日志；
2.  业务数据；
3.  竞品数据。

### 1.1 用户行为日志

日志数据很好理解，就是用户访问我们的网站时，系统记录的各种各样的日志，这些日志记录了用户的行为，比如搜索商品、浏览详情页、下单、评价…… 电商网站最核心的链路：搜索、筛选、详情页、购物车、下单、支付、评价。

那么，对于一个有着 1000 万注册用户的电商网站，每天会产生多少日志数据呢？我们来估算下：

假设日活用户 300W，每个用户每天浏览网站共有 100 次行为操作（这已经算是比较高的了），那么总共的用户行为日志就是 3 亿 / 天。

### 1.2 业务数据

电商网站有大量的表，假设有 100 张表，每张表每天都涉及大量的数据库增删改操作，每次增删改就算一条数据变更记录。那么，假设一笔订单涉及 5 次增删改操作，一天 50w 订单，就有 250w 次操作，100 张表大约就算 2 亿次操作。

所以，数据库每天最终会有 2 亿条的变更记录。

### 1.3 竞品数据

电商网站一般都会用爬虫抓竞争对手网站的商品数据。假设有三个同类的竞争对手网站，每个网站的商品数量在 100 万左右，那么每天爬虫就需要爬 300 万条数据。由于每个商品每天的信息在不停变化，所以爬虫可能需要不停地抓取对方网站的数据，假设每隔 10 分钟抓取一次，那么每个商品一天要抓取`60 / 10 * 24 ≈ 150`次，300 万商品就是 5 亿数据。

* * *

总结，经过上面的分析，对于一个 1000W 用户的电商网站，每天大约会产生`3+2+5=10`亿的数据。这些数据经过 Kafka 的采集，可以用来做用户行为分析、网站运营分析、竞争对手分析，协助网站的产品经理、运营人员、企业高层把控网站运营状况，以此做出对应决策。

![](http://image.skjava.com/article/series/kafka/202307312120510011.png)

> 我上面的这些分析只是一个经验预估，实际生产环境，我们需要以压测产生的实际数据为准进行评估。

二、集群规划
------

经过上面的背景介绍，我们再来看下在这种每日 10 亿数据量的场景下，Kafka 会有哪些性能问题？我们生产环境的 Kafka 集群应该如何来规划和部署？

### 2.1 峰值并发量

先来计算下峰值并发量，对于一个电商平台来说，大部分流量来自每日 8:00- 24:00 这 16 个小时内，根据 2/8 定理——80% 的交易发生在 20% 的时间，所以峰值流量估算如下：

```
    1000000000 * 0.8 / (16 * 0.2 * 60 * 60) = 69444


```

也就是说，日数据量达到 10 亿时，每日的峰值 QPS 可能达到 6W， **Kafka 集群需要能抗住高峰期的 6 万 QPS** 。

一般来说，在公司预算充足的情况下，会尽量控制高峰 QPS 占集群总 QPS 的 30% 左右，也就是说假设峰值 QPS 是 6W，那么集群的总 QPS 达到 20W 是一个比较安全的水平。

> 笔者 17 年的时候，曾经与支付宝、微信、京东金融等第三方支付机构搞过双 11 联合压测演练，当时我们的快捷支付子系统做改造，作为上游应用，预期是能抗住这些机构每秒 1 万 TPS（注意，这里是 TPS）的交易，但是出于安全性考虑，实际压测是要达到总 TPS 的 30% 的目标，也就是抗住 4 万左右 TPS。

### 2.2 数据量

Kafka 集群默认保留最近 7 天的数据。 那么， 每天 10 亿数据，假设每个 Topic 的分区有 2 个副本，那么每天 Kafka 在磁盘上需要保留 10 亿 * 2 = 20 亿数据，7 天一共 140 亿数据。

假设每条数据 1kb，140 亿条数据大约就是 12TB，也就是说 **整个 Kafka 集群的磁盘空间至少需要容纳 12TB 的数据** 。

> 事实上，很多 MySql 同步的 binlog 日志是到不了 1kb 的，也就几十字节，几百个字节；用户行为日志，也不一定有 1kb / 条，所以具体还是看你们公司采集的数据，根据线上的运行情况估算一下平均每条数据有多大。

### 2.3 机器配置

接着，我们继续看具体到机器配置该如何选型，其实无非就是从内存、CPU、硬盘、网卡等方面考量。单台物理机部署 Kafka，抗个 3 万到 4 万 QPS 没啥问题，所以 20 万 QPS 大概要 5 台物理机。

#### 内存

Kafka 集群部署时，对内存的规划是很有讲究的，它大量用到了内存映射和零拷贝，写数据基本上优先让数据写入 OS Cache，消费时也优先从 OS Cache 里读取。虽然 Kafka Broker 本身采用 Scala 语言开发，基于 JVM，但事实上 Kafka 并没有在 JVM 堆内存里放入过多的数据，所以不需要给 Kafka Jvm 堆内存分配太大的空间，基本上 5G 就够了。

所以，部署 Kafka 集群的机器，应该 **重点考虑给机器的 OS Cache 分配较大的空间** ，这块空间越大，能够缓存的数据就越多。那么到底应该分配多大的内存空间呢？

我们已经知道，Kafka 的日志文件是以分区（Partition）为维度划分的，且每个分区的日志文件是分段的，读写基本都是针对最新的那个分段日志，所以 **最理想情况是让每个分区的最新分段日志都能够缓存在 OS Cache 中** 。

假设集群一共有 100 个 Topic，每个 Topic 有 6 个 Partition，读写都是针对 Leader Partition 的，总共就是`100 * 6 = 600`个 Leader Partition，平均到 6 台机器上去，每台机器 100 个 Partition，每个 Partition 的最新分段日志文件大小默认是 1GB，所以单台机器上，最新分段日志文件总大小是 100G。

所以说，理想情况下，单台机器如果有 100GB 内存给 OS Cache 的话，该机器上的所有 Partition 的最新分段日志数据都可以缓存到 OS Cache 里了。一般来说，一个 1G 的分段日志大约能存储几千万条消息，但 **消费比较频繁的一般也就是最新的 10% 的数据，所以基本只要保证最新写入的 10% 的数据驻留在内存中就可以了** 。

总结一下，Kafka 的机器对内存要求较高，内存容量一般根据总分区数计算，保证一台机器上所有分区的最新分段日志文件的前 10% 数据能够被缓存，以 100 个 Topic，每个 Topic6 个分区计算，6 台机器每台大约需要`100 * 6/6 * 1 * 10% = 10G`。所以 **生产环境的 Kafka 机器，一般都会用 16G 以上内存 (JVM 分配一部分内存)** 。

#### CPU

再来看下 CPU 规划，这个主要就是看 Kafka Broker 进程里会有多少个线程。如果线程特别多，但是 CPU 核很少，就会导致机器的 CPU 负载很高，整体工作线程的执行效率不高。

Kafka Broker 后台一般都会有几百个线程运行，比如 Acceptor 线程、Processor 线程（默认 3 个）、Handler 线程（默认 8 个），日志清理线程等等。所以 4 核肯定是不行的，一般建议生产环境 16 核以上。

#### 网卡

网卡这块的话，现在一般就是在 **千兆网卡（1GB / s）** 和万兆网卡（10GB / s）之间选择，主要考虑数据传输量的大小。

高峰期每秒 6 万 QPS，也就是 60mb/s 的数据量，同时 Kafka Broker 之间会进行数据同步，所以多估算一些，假设按照 5 倍估算，每秒大概传输 300mb 左右的数据，所以千兆网卡基本足够了。

#### 硬盘

硬盘主要是考虑两方面：容量和类型。

类型的话，主要就是 SSD 固态硬盘和机械硬盘的选型，SSD 快在磁盘的随机读写，所以对于 MySQL 集群这类系统，用 SSD 可以大幅提升读写性能。但是，对于 Kafka 来说是否必要呢？Kafka 采用的是顺序写日志，机械硬盘的顺序写性能和 SSD 是差不多的，除非你的公司真不差钱，否则 **用机械硬盘就可以了** 。

容量的话，看给 Kafka 集群分配多少台机器，假设总数据量是 12TB，分 6 台物理机，那么每台 2TB 的硬盘容量就够了。

* * *

综上所述，在峰值请求 6 万 QPS，日数据量 12TB 的场景下，可以这样用 5 台物理机搭建 Kafka 集群，每台机器的配置如下：

*   硬盘：2 块 1-2TB 的机械硬盘，7200 转；
*   内存：16GB，JVM 分配 6G，剩余的给 OS Cache；
*   CPU：16 核
*   网络：千兆网卡

三、参数配置
------

Kafka 集群规划完成后，还需要对机器进行一些基本的调优。OS 层面的东西就不赘述了，一般由公司运维人员进行调优并分配机器，主要来看下 Kafka 自身的一些参数设置。

**broker.id**  
这个是每个 broker 的唯一 id。

**log.dirs**  
Kafka 的所有数据写入到这个目录下的硬盘文件中，可以设置多个目录，这样 Kafka 可以将数据分散到多块硬盘，提升吞吐量。

**zookeeper.connect**  
Zookeeper 集群地址。

**listeners**  
Broker 监听客户端发起请求的端口号。

**unclean.leader.election.enable**  
是否允许 OSR 列表中的 Follower 选举为新的 Leader，1.0 版本后的默认值为 false。

**delete.topic.enable**  
是否允许删除 Topic，默认值为 true。

**log.retention.hours**  
日志保留时间，默认 7 天。

**log.retention.bytes**  
分区的数据量如果超过了该值，就会自动清理数据，默认值 - 1，表示不按照这个策略来清理。这个参数一般不常用。

**min.insync.replicas**  
写入消息时，要求 ISR 列表中至少有几个节点才能写入成功，一般与`acks = -1`配合起来使用。

**num.network.threads**  
负责转发请求给 Woker 线程的网络请求处理线程的数量，默认值是 3，高负载场景下可以设置大一些。

**num.io.threads**  
实际处理请求的线程数量，默认值是 8，高负载场景下可以设置大一些。

**message.max.bytes**  
Broker 能接受的最大消息大小，默认是 977kb，生产一般会设置大一些，比如 10mb。

**log.flush.interval.messages**  
每次刷盘时的消息数量

**log.flush.interval.ms**  
刷盘间隔

**JVM 参数**

Kafka 的 JVM 配置是在启动脚本中`bin/kafka-start-server.sh`。